---
title: "Session 3: Bayesian mixed effects regression"
author: 'Angeline Tsui'
date: '`r Sys.Date()`'
output:
  tufte::tufte_html:
    toc: yes
    toc_depth: 1
  tufte::tufte_handout:
    citation_package: natbib
    latex_engine: pdflatex
  tufte::tufte_book:
    citation_package: natbib
    latex_engine: pdflatex
link-citations: yes
bibliography: library.bib
---

```{r, echo=FALSE}
library(knitr)
opts_chunk$set(echo=TRUE, 
               warning=FALSE, message=FALSE, 
               cache=FALSE)
```

This document is developed by [Angeline Tsui](mailto:angelinetsui@gmail.com), and all documents can be found [here](https://).

# Introduction

This short tutorial covers some basic concepts of mixed-effect models and how to run Bayesian mixed-effect model in R. 

<!-- We will use the following tools: -->

<!-- * R, R Studio, R Markdown, and the tidyverse, brms R packages) -->

## Learning goals

By the end of this class, you will have a basic understanding of the following:

* **A mixed-effect model** 
* **The differences between fixed- and random-effect** 
* **The advantage of running a Bayesian mixed-effect model** 
* **Running Bayesian mixed-effect model using brms in R** 

# Quick overview: Regression 

## What is a regression?

We often use a regression to model a relationship between the independent variable $IV_i$ and dependent variable $DV$. For example, a simple form of a linear regression model can be expressed using the following equation:

$$
\text{DV} = \beta_0 + \beta_i{IV_i} + \epsilon 
$$
The $\beta_0$ is the intercept of the regression model, indicating the expected value of $DV$ when all $IV_i$ are zero. To understand the relationship between $DV$ and a particular $IV$, we can examine the regression coefficients: $\beta_i$. The $\beta_i$ indicates how $DV$ change when there is a one unit of change in $IV_i$. Thus, the $\beta_i$ indicates the strength and direction of the relationship between the $DV$ and $IV_i$.

Under the frequentest approach, we determine whether the relationship between the $DV$ and $IV_i$ is statistically significant and also use the regression model to make prediction of the $DV$ value based on specific amount of $IV_i$ values.  

Typically regresion models have several assumptions, they include:
1. Linearity between the $DV$ and $IV_i$
2. Residuals are uncorrelated with one another
3. Residuals have an expected value of zero
4. Variance of residuals is constant across $IV_i$, also known as homoscedasticity
5. No multicollinearity
6. (Optional) Residuals are normally distributed

In Developmental research, we often collect data repeatedly from one individual (e.g., one child) as we are interested in the development of the children's ability over time. We cannot simply use regression models to analyze our data because we necessarily violate assumption 2: Residuals are uncorrelated with one another. In this case, we can use mixed-effect model to analyze this kind of data.

# Frequestist approach: Mixed-effect under 

## What is a mixed-effect model?

Mixed-effect model is a statistical model that contains both fixed effects and random effects, and is widely used to model repeated measurements. Fixed effect are the typical $IV_i$ that we control for in a regression model, thus fixed effect are the population average effect of the $IV_i$ to the $DV$. To model the non-independece between DV within a repeated measure design, we can add random effects that capture the idiosyncratic individual differences between participants. Of course, random effects are not only bounded by the level of participants, but also can be bounded by the level of other grouping factors (e.g., laboratories). In general, random effects model the variations of the observations at the level of some grouping factors. 

Let us take a look at the [ManyBabies 1 (MB1) dataset](https://github.com/manybabies/mb1-analysis-public.git) for an illustration of how mixed-effect model can help us model repeated measurement.

In MB1, we investigated whether monolingual infants across 67 laboratories show a preference for listening to infant-directed speech (baby talk; IDS) over adult-directed speech (ADS). In this experiment, we tested infants with 16 trials where half of the trials were in IDS and the other half were in ADS. Given that repeated measure design, the mixed-effect model is a ideal method to control for the random effects of individual infants' preference for IDS over ADS. Furthermore, as we will see in the dataset, there are a lot of missing data as not all infants can complete all 16 trials. In traditional repeated ANOVA, we will either need to discard participants with missing data or use imputation method to fill out missing data. In contrast, we do not need to do that in a mixed-effect model as this model allows missing data by allocating less weight to participants with less data in the model. 

MB1 data analysis

### Step 1: Packages
```{r}
library(lme4)
library(lmerTest)
library(tidyverse)
```

### Step 2: Data import and cleaning

In this analysis, let us only focus on the laboratories that used Headturn procedure (HPP) in the analysis for a simple illstration

```{r}
mb1_data <- read_csv("https://raw.githubusercontent.com/manybabies/mb1-analysis-public/master/processed_data/03_data_trial_main.csv") %>% 
            filter(method == "hpp") %>%  #only look at HPP data
            drop_na(.) %>%  #let us drop NA for simplicity
            mutate('Language background' = as.factor(ifelse(nae == T, 'North American English', 'non North American English'))) #rename nae for better labeling
       
```


### Step 3: Visualization

Let us look at the data and see infants' preference for IDS over ADS across different age and language backgrounds.

```{r}
mb1_data$age_group <- factor(mb1_data$age_group, 
                             levels = c("3-6 mo", "6-9 mo", "9-12 mo", "12-15 mo")) #fixing the order of age group

mb1_data$trial_type <- factor(mb1_data$trial_type, 
                             levels = c("IDS", "ADS")) #fixing the order of trial_type an d

ggplot(data = mb1_data, aes(x = trial_num, y = looking_time, color = trial_type)) +
  geom_point(alpha = 0.03, position = "jitter") +
  geom_smooth(method = "lm", se = FALSE) +
  facet_wrap(`Language background`~age_group, ncol = 3, nrow = 3) +
  ylab("Looking time") +
  xlab("Trial number") + 
  scale_color_manual(values = c("red", "blue")) +
  labs(color = "Test trial type") +
  theme_classic()
```

We can notice a few things:
1) Older infants tend to look less than younger infants (at least for North American English infants)
2) All infants look less over-time, but older infants appear to have a faster rate of looking time decline than younger infants.
2) The gap between IDS and ADS is larger for older infants, suggesting that IDS preference is stronger for older infants. 
3) North American English infants generally look longer to the the stimuli (North American English speech) than nin North American English infants
4) The gap between IDS and ADS is larger for North American English infants in comparison to non North American English infants, suggesting that North American English infants may show stronger IDS preference than non North American English infants.

### Step 4: Analyzing the data

For simplicity, we focus on the random effects at the infant level (group) in this analysis. Based on the plot above, there are possibilities that infants differ from each other on (i) the magnitude of IDS preference (ii) rate of looking time decline over time. So in the following analyses, we would adopt the "Keep it maximal" approach (Barr et al., 2013) where we will include the maximal random effects structure justified by the design. So we will try including an interaction term between IDS preference and rate of looking time decline as a random slope at the infant group level. 

On the other hand, we will control for the main fixed effects: age in months, trial type (IDS preference), trial number, trial order, language background and gender in the analysis. As these main effects can also interact with the IDS preference (i.e., these factors can influence the magnitude of IDS preference), we will also model the interaction effects of the main fixed-effects and IDS preference as well. 

In the following model, our DV is a log-transformed looking time following Csibra et al (2016) suggestion as well

$$
\text{log looking time} = 1 + 
\text{age * IDS} + 
\text{trial number * IDS} + 
\text{trial order * IDS} + 
\text{language background * IDS} + 
\text{gender * IDS} + 
(1 + \text{trial number} * \text{IDS} | \text{infant})
$$

Lmer model
```{r}
mb1_data <- mb1_data %>% 
            mutate(center_age_mo = as.numeric(scale(age_mo, scale = FALSE)),
                   center_trial_num = as.numeric(scale(trial_num, scale = FALSE)),
                   center_trial_order = as.numeric(scale(trial_order, scale = FALSE)),
                   log_look_time = log(looking_time)
                   ) %>% 
  drop_na(.) %>% 
  mutate(trial_type = ifelse(trial_type == "IDS", 1, 0))



Freq_model <- lmer(log_look_time ~ center_age_mo:trial_type + center_trial_num:trial_type + center_trial_order:trial_type + nae:trial_type + gender:trial_type + (1 | center_trial_num:trial_type), control=lmerControl(optimizer="bobyqa"), #using an optimizer that aligns with the version in MB1 and MB1B
                   data = mb1_data) 

summary(Freq_model)
```

# Bayesian approach: Mixed-effect model

### Step 1: Packages
```{r}
library(brms)
library(tidybayes)
library(bayesplot)
library(rstanarm)
```

### Step 2: Data Analysis and visualization

Before running a model with prior, let us run the model without the default prior.

```{r}
Bayes_model_default <- brm(looking_time ~ center_age_mo:trial_type + center_trial_num:trial_type + center_trial_order:trial_type + nae:trial_type + gender:trial_type + (1 | center_trial_num:trial_type),
                   family = lognormal(),
                   data = mb1_data,
                   warmup = 1000, 
                   iter = 4000, 
                   cores = 2,
                   chains = 2, 
                   seed = 123,
                   save_all_pars = TRUE, 
                   control = list(adapt_delta = 0.95),
                   file="mb1_bayes.mod")

print(summary(Bayes_model_default), digits = 3)
```

Let us visualize the posterior distribution of some parameters.
```{r}
posterior_default <- as.matrix(Bayes_model_default)

mcmc_areas(posterior_default,
           pars = c("b_trial_type:center_age_mo",
                    "b_center_trial_num:trial_type",
                    "b_trial_type:center_trial_order",
                    "b_trial_type:naeTRUE"), #you can select which parameter(s) you want to plot
           prob = 0.95) + 
  ggtitle("Posterior distributions", 
          "with medians and 95% credit intervals")

pp_check(Bayes_model_default) #the posterior predictive checks do not look good at all.....
```
This plot shows the densities of four important parameter estimates. For each density, the dark blue line represents the point estimate (median) and light blue area represents the 95% credibility intervals. We can use this to get a sense of which parameter(s) has/have a posterior distribution(s) that does not contain zero and how wide the distribution (flat or pointy). 

Thus far, we did the Bayesian analysis using the default priors. But the most important feature of Bayesian analysis is that we can incoporate our priors in our analysis. So in the following 

### Step 3: Incoporate priors in our analyses

Let us take a look at how many prior parameters that we need to set up. 
```{r}
get_prior(looking_time ~ center_age_mo:trial_type + center_trial_num:trial_type + center_trial_order:trial_type + nae:trial_type + gender:trial_type + (1 | center_trial_num:trial_type), data = mb1_data)
```

Note that it also tells us the default priors that we were using in the previous model. For simplicity, let us set the same priors for all coefficients and variances.

Set up priors like this
```{r}
priors <- c(prior(normal(2, 1), class = Intercept),          
            prior(normal(2, 0.25), class = b),
            prior(normal(1, 0.5), class = sd),
            prior(normal(0, 1), class = sigma))  
```

```{r}
Bayes_model_priors <- brm(looking_time ~ center_age_mo:trial_type + center_trial_num:trial_type + center_trial_order:trial_type + nae:trial_type + gender:trial_type + (1 | center_trial_num:trial_type),
                   family = lognormal(),
                   prior = priors,
                   data = mb1_data,
                   warmup = 1000, 
                   iter = 4000, 
                   cores = 2,
                   chains = 2, 
                   seed = 123,
                   save_all_pars = TRUE, 
                   control = list(adapt_delta = 0.99),
                   file="mb1_bayes_priors.mod")

print(summary(Bayes_model_priors), digits = 3)
```

